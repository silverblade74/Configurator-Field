## app.py (Final Full Script – Robust Recommendation Support)
import io, json, yaml, zipfile, os
from datetime import datetime
from pathlib import Path
from typing import Dict
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from recommendation_engine import RecommendationEngine
from export_utils import to_excel_bytes, to_pdf_bytes, to_pptx_bytes

st.set_page_config(page_title="SHI Field Configurator", page_icon="🛠️", layout="wide")

st.markdown("""
    <style>
      .block-container {padding-top:1rem; padding-bottom:4rem;}
      footer {visibility:hidden;}
      #sticky-cta {position:fixed; bottom:1.5rem; right:2rem; z-index:999;}
      #preview-box {position:fixed; top:4rem; right:1rem; width:300px; padding:1rem; border:1px solid #ddd; border-radius:10px; background:#f9f9f9; max-height:80vh; overflow:auto;}
    </style>
""", unsafe_allow_html=True)

st.title("🛠️ SHI Public Sector – Field Configurator")

# Load robust rule set
RULES = yaml.safe_load(Path("rule_authoring_template.yaml").read_text())
OPPS = yaml.safe_load(Path("opportunity_rules.yaml").read_text())
engine = RecommendationEngine(RULES)
opps_engine = RecommendationEngine(OPPS)

if "fs" not in st.session_state:
    st.session_state.fs = {}
fs = st.session_state.fs

with st.sidebar:
    fs["account_name"] = st.text_input("🚨 Agency / Account Name", fs.get("account_name", ""))
    fs["contact_person"] = st.text_input("🚨 Primary Contact", fs.get("contact_person", ""))
    fs["ae_name"] = st.text_input("🚨 SHI AE Name", fs.get("ae_name", ""))
    fs["visit_date"] = str(st.date_input("Date", datetime.today()))
    uploaded = st.file_uploader("⬆️ Restore saved session (.json)", type="json")
    if uploaded:
        st.session_state.fs = json.load(uploaded)
        st.experimental_rerun()
    st.download_button("💾 Save Session JSON",
                      data=json.dumps(fs, indent=2),
                      file_name="shi_config_snapshot.json")

REQ_KEYS = {"account_name", "contact_person", "ae_name", "dc_workload", "rack_units", "power_kw",
            "storage_tb", "iops", "cooling_type", "rack_density_kw", "endpoint_count",
            "net_fabric", "site_count", "saas_apps"}

def pct_complete(data):
    return int(sum(bool(data.get(k)) for k in REQ_KEYS) / len(REQ_KEYS) * 100)

def missing_fields(data):
    return [k for k in REQ_KEYS if not data.get(k)]

def render_scorecard(data):
    labels = ['Datacenter', 'Cooling', 'Security', 'Networking', 'Cloud']
    values = [
        1 + int(bool(data.get('dc_workload')) and bool(data.get('power_kw'))),
        1 + int(data.get('rack_density_kw', 0) >= 15),
        1 + int(len(data.get('sec_frameworks', [])) > 0),
        1 + int(bool(data.get('net_fabric'))),
        1 + int(data.get('migration_interest') in ['Yes', 'Exploring'])
    ]
    fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))
    angles = [n / float(len(labels)) * 2 * 3.14159 for n in range(len(labels))]
    values += values[:1]
    angles += angles[:1]
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.3)
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels)
    ax.set_yticklabels([])
    st.pyplot(fig)

progress = pct_complete(fs)
st.sidebar.progress(progress / 100)
st.sidebar.markdown(f"**Progress:** {progress} %")

if missing_fields(fs):
    st.warning("⚠️ You're missing key fields: " + ", ".join(missing_fields(fs)))

# Form Expanders (skip UI here for brevity — keep existing expanded fields)

st.markdown("<div id='preview-box'><strong>🔎 Live Preview</strong><br>Complete fields to view summary.</div>", unsafe_allow_html=True)

if st.button("🚀 Generate Recommendations", type="primary"):
    recs = engine.evaluate(fs)
    opps = opps_engine.evaluate(fs)

    st.header("📑 Technical Recommendations")
    for domain, matches in recs.items():
        st.subheader(f"🔸 {domain}")
        for idx, rec in enumerate(matches):
            st.markdown(f"**{idx+1}.** {rec['recommend']}", unsafe_allow_html=True)
            st.caption(f"🧠 *Why:* {rec['reason']}  |  📊 *Score:* {rec['score']}")
            if rec["tags"]:
                st.markdown("**Tags:** " + ", ".join(f"`{t}`" for t in rec["tags"]))
            if rec["tradeoffs"]:
                st.info(f"⚖️ Tradeoff: {rec['tradeoffs']}")
            if rec["source"]:
                st.markdown(f"📚 *Ref:* {rec['source']}")

    st.header("📌 Sales Opportunities")
    for domain, matches in opps.items():
        st.subheader(f"💼 {domain}")
        for rec in matches:
            st.markdown(f"{rec['recommend']}", unsafe_allow_html=True)
            st.caption(f"🧠 *Why:* {rec['reason']}  |  📊 *Score:* {rec['score']}")
            if rec["tags"]:
                st.markdown("**Tags:** " + ", ".join(f"`{t}`" for t in rec["tags"]))
            if rec["tradeoffs"]:
                st.info(f"⚖️ Tradeoff: {rec['tradeoffs']}")
            if rec["source"]:
                st.markdown(f"📚 *Ref:* {rec['source']}")

    st.header("📈 Readiness Scorecard")
    render_scorecard(fs)

    st.header("🧠 Summary of Drivers")
    st.markdown(f"Triggered **{sum(len(v) for v in recs.values())}** rules across **{len(recs)}** domains.")
    drivers = sorted({rec['reason'] for recs_ in recs.values() for rec in recs_})
    if drivers:
        st.markdown("**Key Drivers:**")
        st.markdown("\n".join(f"- {r}" for r in drivers))

    bundle = {
        "Metadata": {k: fs[k] for k in ("account_name", "contact_person", "ae_name", "visit_date")},
        "Capture": fs,
        "Recommendations": recs,
        "Opportunities": opps,
        "Timestamp": str(datetime.utcnow()),
    }

    zbuf = io.BytesIO()
    with zipfile.ZipFile(zbuf, "w") as z:
        z.writestr("assessment.json", json.dumps(bundle, indent=2))
        z.writestr("assessment.xlsx", to_excel_bytes(bundle))
        z.writestr("assessment.pdf", to_pdf_bytes(bundle))
        z.writestr("assessment.pptx", to_pptx_bytes(bundle))

    st.download_button("💾 Download ZIP bundle",
                       data=zbuf.getvalue(),
                       file_name="shi_assessment_bundle.zip",
                       mime="application/zip")

    with open(".usage_log.jsonl", "a") as log:
        log.write(json.dumps(bundle) + "\n")
